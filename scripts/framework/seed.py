"""
Script to find seed keyword
"""

import sys
sys.path.append("/home/yichen/crypto_jargon")

import pickle

from tqdm import tqdm
import torch

from environ.framework.seed import cos_sim, search_pos, get_row, get_col
from environ.constants import DATA_PATH, PROCESSED_DATA_PATH
from environ.pretrain.mlm_data_gen import corpus, word_segment
from scripts.train.tokenizer import compound_tokens, tokenizer
from bert4torch.models import build_transformer_model

device = "cuda" if torch.cuda.is_available() else "cpu"


# model dir
cur_load_file = f"{PROCESSED_DATA_PATH}/emb_data/train_20240729101610"
config_path = f"{DATA_PATH}/RoBERTa-wwm-ext/bert_config.json"
checkpoint_path = f"{DATA_PATH}/RoBERTa-wwm-ext/pytorch_model.bin"

corpus_texts = [word_segment(text) for texts in corpus() for text in texts]

 # read from contextual embeddings
with open(f"{PROCESSED_DATA_PATH}/emb/bert_emb.pkl", "rb") as f:
    emb = pickle.load(f)

model = build_transformer_model(
    config_path,
    checkpoint_path,
    segment_vocab_size=0,
    with_mlm=True,
    add_trainer=True,
    output_all_encoded_layers=True,
    compound_tokens=compound_tokens,
).to(device)
model.load_weights(f"{PROCESSED_DATA_PATH}/pretrain/model/" + "model_20.ckpt")

# read from remain.txt(generated by filter.py)
vocab = [line.strip() for line in open(
    f"{PROCESSED_DATA_PATH}/vocab.txt", 'r', encoding='utf-8').readlines()]

# seed keyword search
seed_kw = "比特币"
token_ids, _ = tokenizer.encode(seed_kw)
seed_vec = model.predict([
            torch.tensor([token_ids[1:2]], dtype=torch.long, device=device)
])[0][-2].cpu().detach().numpy()

# traverse the vocab and find most similar words for each criminal seed
# try add them to Keywords.json for your own criminal category